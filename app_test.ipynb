{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from utils import Skipgram, SkipgramNeg, Glove\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glove(\n",
       "  (embedding_center): Embedding(8558, 30)\n",
       "  (embedding_outside): Embedding(8558, 30)\n",
       "  (center_bias): Embedding(8558, 1)\n",
       "  (outside_bias): Embedding(8558, 1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "Data = pickle.load(open('/home/koala/NLP/NPL-A1/data/data.pkl', 'rb'))\n",
    "vocab = Data['vocab']\n",
    "word2index = Data['word2index']\n",
    "voc_size = Data['voc_size']\n",
    "embed_size = Data['emb_size']\n",
    "\n",
    "# Load the models\n",
    "skipgram = Skipgram(voc_size, embed_size)\n",
    "skipgram.load_state_dict(torch.load('/home/koala/NLP/NPL-A1/models/skipgram.pth', map_location=torch.device('cpu')))\n",
    "skipgram.eval()\n",
    "\n",
    "skipgramNeg = SkipgramNeg(voc_size, embed_size)\n",
    "skipgramNeg.load_state_dict(torch.load('/home/koala/NLP/NPL-A1/models/skipgramNEG.pth', map_location=torch.device('cpu')))\n",
    "skipgramNeg.eval()\n",
    "\n",
    "glove = Glove(voc_size, embed_size)\n",
    "glove.load_state_dict(torch.load('/home/koala/NLP/NPL-A1/models/GloVe.pth', map_location=torch.device('cpu')))\n",
    "glove.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(model, user_inputs):\n",
    "\n",
    "    all_word_vectors = torch.stack([model.get_embed(word) for word in vocab])\n",
    "    user_inputs = user_inputs.split()\n",
    "\n",
    "    input_vectors = []\n",
    "\n",
    "    for word in user_inputs:\n",
    "        if word.lower() in vocab:\n",
    "            input_vectors.append(model.get_embed(word.lower()))\n",
    "        else:\n",
    "            input_vectors.append(model.get_embed('<UNK>'))\n",
    "\n",
    "    # Check if input vectors are not empty\n",
    "    if input_vectors:\n",
    "        \n",
    "        # Initialize result_vector with the first vector\n",
    "        result_vector = input_vectors[0]\n",
    "\n",
    "        # Add the rest of the vectors\n",
    "        for vector in input_vectors[1:]:\n",
    "            result_vector += vector\n",
    "    else:\n",
    "        # Handle the case where input_vectors is empty\n",
    "        result_vector = torch.zeros_like(all_word_vectors[0])  # Assuming all vectors have the same size\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    similarities = F.cosine_similarity(result_vector.unsqueeze(0), all_word_vectors)\n",
    "\n",
    "    # Get top 10 similar words\n",
    "    top_indices = torch.argsort(similarities, descending=True)[0][:10]\n",
    "    return [vocab[index.item()] for index in top_indices.view(-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
