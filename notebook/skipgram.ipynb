{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/koala/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Document:\n",
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"We wouldn't be able to do business,\" said a spokesman for\n",
      "  leading Japanese electronics firm Matsushita Electric\n",
      "  Industrial Co Ltd &lt;MC.T>.\n",
      "      \"If the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
      "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
      "  Capel and Co>.\n",
      "      In Taiwan, businessmen and officials are also worried.\n",
      "      \"We are aware of the seriousness of the U.S. Threat against\n",
      "  Japan because it serves as a warning to us,\" said a senior\n",
      "  Taiwanese trade official who asked not to be named.\n",
      "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the U.S.\n",
      "      The surplus helped swell Taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"We must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of U.S. Products, if we\n",
      "  want to defuse problems from possible U.S. Retaliation,\" said\n",
      "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
      "      A senior official of South Korea's trade promotion\n",
      "  association said the trade dispute between the U.S. And Japan\n",
      "  might also lead to pressure on South Korea, whose chief exports\n",
      "  are similar to those of Japan.\n",
      "      Last year South Korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
      "      In Malaysia, trade officers and businessmen said tough\n",
      "  curbs against Japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  U.S.\n",
      "      In Hong Kong, where newspapers have alleged Japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. But other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further U.S. Pressure to block imports.\n",
      "      \"That is a very short-term view,\" said Lawrence Mills,\n",
      "  director-general of the Federation of Hong Kong Industry.\n",
      "      \"If the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. Much more serious for Hong Kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      The U.S. Last year was Hong Kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      The Australian government is awaiting the outcome of trade\n",
      "  talks between the U.S. And Japan with interest and concern,\n",
      "  Industry Minister John Button said in Canberra last Friday.\n",
      "      \"This kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" Button said.\n",
      "      He said Australia's concerns centred on coal and beef,\n",
      "  Australia's two largest exports to Japan and also significant\n",
      "  U.S. Exports to that country.\n",
      "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
      "  a package of economic measures to boost the Japanese economy.\n",
      "      The measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      They also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite Prime Minister\n",
      "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
      "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
      "  Kuroda, Japan's deputy minister of International Trade and\n",
      "  Industry (MITI), are due to meet in Washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Second Document:\n",
      "CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showed vermin consume between seven and 12 pct of China's grain\n",
      "  stocks, the China Daily said.\n",
      "      It also said that each year 1.575 mln tonnes, or 25 pct, of\n",
      "  China's fruit output are left to rot, and 2.1 mln tonnes, or up\n",
      "  to 30 pct, of its vegetables. The paper blamed the waste on\n",
      "  inadequate storage and bad preservation methods.\n",
      "      It said the government had launched a national programme to\n",
      "  reduce waste, calling for improved technology in storage and\n",
      "  preservation, and greater production of additives. The paper\n",
      "  gave no further details.\n",
      "  \n",
      "\n",
      "\n",
      "10788\n"
     ]
    }
   ],
   "source": [
    "# Getting all file IDs from the Reuters corpus\n",
    "file_ids = reuters.fileids()\n",
    "\n",
    "# Creating a corpus where each document is a separate item\n",
    "reuter = [reuters.raw(fileid) for fileid in file_ids]\n",
    "\n",
    "# Print the first document\n",
    "print(\"First Document:\")\n",
    "print(reuter[0])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the second document\n",
    "print(\"Second Document:\")\n",
    "print(reuter[1])\n",
    "\n",
    "print(len(reuter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8557\n",
      "8557\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "corpus = reuters.sents()\n",
    "corpus = corpus[0:2500] \n",
    "\n",
    "# flattening\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# unique words\n",
    "vocabs = list(set(flatten(corpus))) \n",
    "print(len(vocabs))\n",
    "\n",
    "# mapping between word and integer\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75698"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word = 0\n",
    "for sen in corpus:\n",
    "    for w in sen:\n",
    "        total_word += 1\n",
    "total_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if unkown word is seen, return 'UNK'\n",
    "vocabs.append('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['<UNK>'] = 8557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8558"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case we need to use\n",
    "index2word = {v: k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNK>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word[8557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 . Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n",
      "['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.']\n",
      "['But', 'some', 'exporters', 'said', 'that', 'while', 'the', 'conflict', 'would', 'hurt', 'them', 'in', 'the', 'long', '-', 'run', ',', 'in', 'the', 'short', '-', 'term', 'Tokyo', \"'\", 's', 'loss', 'might', 'be', 'their', 'gain', '.']\n",
      "['The', 'U', '.', 'S', '.', 'Has', 'said', 'it', 'will', 'impose', '300', 'mln', 'dlrs', 'of', 'tariffs', 'on', 'imports', 'of', 'Japanese', 'electronics', 'goods', 'on', 'April', '17', ',', 'in', 'retaliation', 'for', 'Japan', \"'\", 's', 'alleged', 'failure', 'to', 'stick', 'to', 'a', 'pact', 'not', 'to', 'sell', 'semiconductors', 'on', 'world', 'markets', 'at', 'below', 'cost', '.']\n",
      "['Unofficial', 'Japanese', 'estimates', 'put', 'the', 'impact', 'of', 'the', 'tariffs', 'at', '10', 'billion', 'dlrs', 'and', 'spokesmen', 'for', 'major', 'electronics', 'firms', 'said', 'they', 'would', 'virtually', 'halt', 'exports', 'of', 'products', 'hit', 'by', 'the', 'new', 'taxes', '.']\n",
      "['\"', 'We', 'wouldn', \"'\", 't', 'be', 'able', 'to', 'do', 'business', ',\"', 'said', 'a', 'spokesman', 'for', 'leading', 'Japanese', 'electronics', 'firm', 'Matsushita', 'Electric', 'Industrial', 'Co', 'Ltd', '&', 'lt', ';', 'MC', '.', 'T', '>.']\n",
      "['\"', 'If', 'the', 'tariffs', 'remain', 'in', 'place', 'for', 'any', 'length', 'of', 'time', 'beyond', 'a', 'few', 'months', 'it', 'will', 'mean', 'the', 'complete', 'erosion', 'of', 'exports', '(', 'of', 'goods', 'subject', 'to', 'tariffs', ')', 'to', 'the', 'U', '.', 'S', '.,\"', 'said', 'Tom', 'Murtha', ',', 'a', 'stock', 'analyst', 'at', 'the', 'Tokyo', 'office', 'of', 'broker', '&', 'lt', ';', 'James', 'Capel', 'and', 'Co', '>.']\n",
      "['In', 'Taiwan', ',', 'businessmen', 'and', 'officials', 'are', 'also', 'worried', '.']\n",
      "['\"', 'We', 'are', 'aware', 'of', 'the', 'seriousness', 'of', 'the', 'U', '.', 'S', '.']\n",
      "['Threat', 'against', 'Japan', 'because', 'it', 'serves', 'as', 'a', 'warning', 'to', 'us', ',\"', 'said', 'a', 'senior', 'Taiwanese', 'trade', 'official', 'who', 'asked', 'not', 'to', 'be', 'named', '.']\n",
      "['Taiwan', 'had', 'a', 'trade', 'trade', 'surplus', 'of', '15', '.', '6', 'billion', 'dlrs', 'last', 'year', ',', '95', 'pct', 'of', 'it', 'with', 'the', 'U', '.', 'S', '.']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for c in corpus:\n",
    "    print(c)\n",
    "    # Stop after ten\n",
    "    i+=1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window size 2\n",
    "\n",
    "#create pairs of center word, and outside word\n",
    "def random_batch(batch_size, corpus):\n",
    "\n",
    "    skipgrams = []\n",
    "\n",
    "    #loop each corpus\n",
    "    for doc in corpus:\n",
    "        #look from the 3rd word until third last word\n",
    "        for i in range(2, len(doc)-2):\n",
    "            #center word\n",
    "            center = word2index[doc[i]]\n",
    "            #outside words = 2 words\n",
    "            outside = (word2index[doc[i-2]], word2index[doc[i-1]], word2index[doc[i+1]], word2index[doc[i+2]])\n",
    "            #for each of these four outside words, we gonna append to a list\n",
    "            for each_out in outside:\n",
    "                skipgrams.append([center, each_out])\n",
    "                #center, outside1;   center, outside2\n",
    "                \n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    for index in random_index:\n",
    "        inputs.append([skipgrams[index][0]])\n",
    "        labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(inputs), np.array(labels)\n",
    "            \n",
    "x, y = random_batch(2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocabs = len(vocabs)\n",
    "emb_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(all_vocabs, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([1])\n",
    "\n",
    "embedding(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.LongTensor(x)\n",
    "\n",
    "embedding(x_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.2948e-01, -1.2965e+00, -2.9147e-01, -1.3440e-01,  3.7328e-01,\n",
      "          -8.2109e-01,  1.2141e+00,  6.8356e-01, -1.5652e+00,  1.4925e+00,\n",
      "           1.3388e-01,  1.3843e+00,  1.5201e+00,  3.9130e-01, -5.9786e-01,\n",
      "          -9.7921e-01, -4.4298e-02, -2.1049e-01,  1.3406e+00,  4.6913e-01,\n",
      "          -3.8105e-02, -1.8151e+00,  1.2973e+00,  1.3796e+00, -1.6454e+00,\n",
      "          -1.2017e-01,  1.1927e+00,  3.7965e-02, -1.4467e-01, -7.0912e-01]],\n",
      "\n",
      "        [[-6.2999e-01,  1.0493e+00,  5.6145e-01,  1.3875e+00,  1.0629e+00,\n",
      "           6.1920e-01, -2.5575e+00, -1.4297e+00, -2.1945e+00,  3.7377e-02,\n",
      "           6.1118e-01,  3.3675e-01, -1.9051e+00, -1.2329e-01,  8.9478e-01,\n",
      "          -1.9199e+00, -2.1698e+00, -8.0637e-01, -1.2002e+00, -1.7894e+00,\n",
      "          -1.2800e+00,  1.0466e-01,  5.6365e-01,  1.9682e-03, -3.7445e-02,\n",
      "           1.4580e+00,  9.0957e-01, -4.1888e-01,  6.4385e-01, -3.7139e-01]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding(x_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n",
    "        outside_embedding    = self.embedding_center(outside) #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embedding = self.embedding_center(all_vocabs) #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
    "        #batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1) \n",
    "\n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
    "        #batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size) \n",
    "        \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n",
    "\n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 8555, 8556, 8557],\n",
       "        [   0,    1,    2,  ..., 8555, 8556, 8557]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "voc_size   = len(vocabs)\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(8558, 30)\n",
       "  (embedding_outside): Embedding(8558, 30)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Skipgram(voc_size, emb_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 8558])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.LongTensor(x)\n",
    "label_tensor = torch.LongTensor(y)\n",
    "print(input_tensor.shape)\n",
    "print(label_tensor.shape)\n",
    "print(all_vocabs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "loss = model(input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.3161, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model      = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch    100 | Loss: 35.472145 | Time: 00m 28s\n",
      "Epoch    200 | Loss: 33.157692 | Time: 00m 55s\n",
      "Epoch    300 | Loss: 31.314760 | Time: 01m 23s\n",
      "Epoch    400 | Loss: 32.280010 | Time: 01m 51s\n",
      "Epoch    500 | Loss: 31.401640 | Time: 02m 19s\n",
      "Epoch    600 | Loss: 26.410089 | Time: 02m 47s\n",
      "Epoch    700 | Loss: 20.925999 | Time: 03m 16s\n",
      "Epoch    800 | Loss: 31.999252 | Time: 03m 45s\n",
      "Epoch    900 | Loss: 29.734051 | Time: 04m 14s\n",
      "Epoch   1000 | Loss: 35.739899 | Time: 04m 43s\n",
      "Training completed in 04m 43s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Check if GPU with CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move your model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 1000\n",
    "print_interval = 100  # Interval to print the loss\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Get batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
    "    \n",
    "    # Move data to the GPU\n",
    "    input_tensor = torch.LongTensor(input_batch).to(device)\n",
    "    label_tensor = torch.LongTensor(label_batch).to(device)\n",
    "    all_vocabs = all_vocabs.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "    \n",
    "    # Backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % print_interval == 0:\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "        mins, secs = divmod(elapsed_time, 60)\n",
    "        print(f\"Epoch {epoch+1:6.0f} | Loss: {loss.item():2.6f} | Time: {int(mins):02d}m {int(secs):02d}s\")\n",
    "\n",
    "# End of training\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_mins, total_secs = divmod(total_time, 60)\n",
    "print(f\"Training completed in {int(total_mins):02d}m {int(total_secs):02d}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/skipgram.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = {\n",
    "    'vocab': vocabs,\n",
    "    'word2index': word2index,\n",
    "    'voc_size': voc_size,\n",
    "    'emb_size': emb_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(Data,open('./data/data.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
