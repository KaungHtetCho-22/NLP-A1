{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_capitals = 'data/capital-common.txt'\n",
    "file_path_past = 'data/past-tense.txt'\n",
    "file_path_given_dataset = 'data/similarity_gold_standard.txt'\n",
    "\n",
    "with open(file_path_capitals, 'r') as file:\n",
    "    capital_common = file.readlines()\n",
    "\n",
    "with open(file_path_past, 'r') as file:\n",
    "    past_tense = file.readlines()\n",
    "\n",
    "with open(file_path_given_dataset, 'r') as file:\n",
    "    similarity_gold_standard = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pickle\n",
    "\n",
    "import pickle\n",
    "with open('data/data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "voc_size = loaded_data['voc_size']\n",
    "emb_size = loaded_data['emb_size']\n",
    "word2index = loaded_data['word2index']\n",
    "vocab = loaded_data['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athens Greece Baghdad Iraq\n",
      "\n",
      "Athens\n",
      "Greece\n",
      "Baghdad\n",
      "Iraq\n"
     ]
    }
   ],
   "source": [
    "# sample word extraction\n",
    "\n",
    "for line in capital_common:\n",
    "    print(line)\n",
    "    break\n",
    "\n",
    "words = line.split()\n",
    "\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Skipgram,SkipgramNeg,Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(8558, 30)\n",
       "  (embedding_outside): Embedding(8558, 30)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load skipgram.pth model\n",
    "\n",
    "skipgram = Skipgram(voc_size, emb_size)\n",
    "skipgram.load_state_dict(torch.load('models/skipgram.pth',map_location=torch.device('cpu')))\n",
    "skipgram.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipgramNeg(\n",
       "  (embedding_center): Embedding(8558, 30)\n",
       "  (embedding_outside): Embedding(8558, 30)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load skipgramNEG.pth model\n",
    "\n",
    "skipgramNEG = SkipgramNeg(voc_size, emb_size)\n",
    "skipgramNEG.load_state_dict(torch.load('models/skipgramNEG.pth',map_location=torch.device('cpu')))\n",
    "skipgramNEG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glove(\n",
       "  (embedding_center): Embedding(8558, 30)\n",
       "  (embedding_outside): Embedding(8558, 30)\n",
       "  (center_bias): Embedding(8558, 1)\n",
       "  (outside_bias): Embedding(8558, 1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load GloVe.pth model\n",
    "\n",
    "GloVe = Glove(voc_size, emb_size)\n",
    "GloVe.load_state_dict(torch.load('models/GloVe.pth',map_location=torch.device('cpu')))\n",
    "GloVe.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Gensim model\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.100d.txt')  #search on the google\n",
    "gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True, limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sematic and syntatic calcualtion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30])\n"
     ]
    }
   ],
   "source": [
    "# tensor_size testing\n",
    "\n",
    "tensor_size = skipgram.get_embed('FEAR') \n",
    "print(tensor_size.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorized_words(vocab, model):\n",
    "    word_vectors = []\n",
    "\n",
    "    # Iterate over words in vocab\n",
    "    \n",
    "    for word in vocab:\n",
    "        vector = model.get_embed(word)\n",
    "        word_vectors.append(vector)\n",
    "\n",
    "    vectorized_words = torch.stack(word_vectors)\n",
    "\n",
    "    return vectorized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_word_technique(lines, model, vocab):\n",
    "\n",
    "    correct = 0\n",
    "    vectorized_words = prepare_vectorized_words(vocab, model) \n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split() # Example: 'Athens', 'Greece', Baghdad Iraq'\n",
    "\n",
    "        # Ensure all words are in vocabulary\n",
    "        vec = [model.get_embed(word if word in vocab else '<UNK>') for word in words]\n",
    "\n",
    "        # Vector algebraic operation: vec2 - vec1 + vec3\n",
    "        final_vector = vec[1] - vec[0] + vec[2]\n",
    "\n",
    "        final_vector = final_vector.unsqueeze(0)\n",
    "\n",
    "        # Cosine similarities\n",
    "        cos_sim = F.cosine_similarity(final_vector, vectorized_words)\n",
    "\n",
    "        # Find the index of the word with the highest similarity\n",
    "        closest_word_index = torch.argmax(cos_sim).item()\n",
    "        closest_word = vocab[closest_word_index]\n",
    "        \n",
    "        if closest_word == words[3]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = (correct / len(lines)) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in words:\n",
    "#     vec1 = skipgram.get_embed(words[0])\n",
    "#     vec2 = skipgram.get_embed(words[1])\n",
    "#     vec3 = skipgram.get_embed(words[2])\n",
    "\n",
    "#     result_vector = vec2[0] - vec1[0] + vec3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec1 = skipgram.get_embed('FEAR')\n",
    "# vec2 = skipgram.get_embed('ASIAN')\n",
    "# vec3 = skipgram.get_embed('JAPAN')\n",
    "\n",
    "# result2 = vec2[0] - vec1[0] + vec3[0]\n",
    "# print(result2)\n",
    "# print(result2.size())\n",
    "# result3 = result2.unsqueeze(0)\n",
    "# print(result3.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferencing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(capital_common, skipgram, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(past_tense, skipgram, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### skipgramNEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(capital_common, skipgramNEG, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(past_tense, skipgramNEG, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(capital_common, GloVe, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_word_technique(past_tense, GloVe, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntactic and semantic similarity function for gensim\n",
    "\n",
    "def analogy(lines):\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    # Vector algebraic operation: vec2 - vec1 + vec3\n",
    "    \n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i].lower() # Convert all words to lower case\n",
    "            if words[i] not in gensim: # Check if gensim contains the word\n",
    "                words[i] = 'unknown' # Set as unknown if not\n",
    "        \n",
    "        # used gensim's built in function \n",
    "        result = gensim.most_similar(positive=[words[2], words[1]], negative=[words[0]])\n",
    "\n",
    "        # Get the closest word\n",
    "        closest_word = result[0][0]\n",
    "        if closest_word == words[3]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = (correct / len(lines)) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.87351778656127"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(capital_common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.44871794871795"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(past_tense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding correlation between modelsâ€™ dot product and offset_word_technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and create a list of tuples\n",
    "with open('data/similarity_gold_standard.txt', 'r') as file:\n",
    "    given_dataset = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a = a.flatten()  # Flatten the array to 1D\n",
    "    b = b.flatten()  # Flatten the array to 1D\n",
    "    cos_sim = dot(a, b) / (norm(a) * norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(lines, model):\n",
    "\n",
    "    y_truth = []; y_predict = []\n",
    "\n",
    "    # input words from .txt\n",
    "    # append y-true value to y_truth vector\n",
    "    \n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        \n",
    "        vec = []\n",
    "        for word in words[:2]:\n",
    "            try:\n",
    "                vec.append(model.get_embed(word).detach().numpy())\n",
    "            except:\n",
    "                vec.append(model.get_embed('<UNK>').detach().numpy())\n",
    "                            \n",
    "        y_truth.append(float(words[2]))\n",
    "        y_predict.append(cos_sim(np.array(vec[0]), np.array(vec[1])))\n",
    "    \n",
    "    # spearmanr correlation \n",
    "    correlation_score, p_value = spearmanr(y_truth, y_predict)\n",
    "    print(f'Correlation score: {correlation_score:.2f}, P-value: {p_value:.2f}')\n",
    "    return correlation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation score: 0.11, P-value: 0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10802765308471039"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skipgram\n",
    "\n",
    "correlation(similarity_gold_standard, skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation score: 0.10, P-value: 0.18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09511098355406604"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skipgramNEG\n",
    "\n",
    "correlation(similarity_gold_standard, skipgramNEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation score: 0.16, P-value: 0.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1636033039515042"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GloVe\n",
    "\n",
    "correlation(similarity_gold_standard, GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_vector function is the reason why I seperate the correlation function\n",
    "\n",
    "def correlation_gensim(lines, model):\n",
    "\n",
    "    y_truth = []; y_predict = []\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        \n",
    "        vec = []\n",
    "        for word in words[:2]:\n",
    "            try:\n",
    "                vec.append(model.get_vector(word)) \n",
    "            except:\n",
    "                vec.append(model.get_vector('unknown'))\n",
    "                            \n",
    "        y_truth.append(float(words[2]))\n",
    "        y_predict.append(cos_sim(np.array(vec[0]), np.array(vec[1])))\n",
    "        \n",
    "    correlation_score, p_value = spearmanr(y_truth, y_predict)\n",
    "    print(f'Correlation score: {correlation_score:.2f}, P-value: {p_value:.2f}')\n",
    "    return correlation_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation score: 0.60, P-value: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5958258410203774"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_gensim(similarity_gold_standard, gensim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
